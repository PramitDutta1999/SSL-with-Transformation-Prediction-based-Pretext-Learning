{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSlb8ds1ih6c",
        "outputId": "0b5a8a97-5608-40df-eb7b-1329e313f331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/transformed_oct.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "XdkMQq6QinZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout, BatchNormalization, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionV3, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "IzEAFdFNipVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretext_path = '/content/Pretext Learning'\n",
        "pretext_datagen = ImageDataGenerator(rescale=1./255)\n",
        "pretext_generator = pretext_datagen.flow_from_directory(\n",
        "    pretext_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6u3Lmb6irfA",
        "outputId": "f07dd05a-fea0-43db-d23f-a20e76c1bb19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 65279 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Pretext task\n",
        "#x = base_model.get_layer(\"conv3_block4_out\").output\n",
        "x = base_model.layers[-1].output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "pretext_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze layers\n",
        "for layer in base_model.layers[-10:]:  # Unfreeze the last 10 layers, for example\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile\n",
        "pretext_model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "p8cXPEItiuT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on pretext\n",
        "pretext_model.fit(pretext_generator, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTiR0FY8kcRa",
        "outputId": "a20b75ea-5d89-403b-c6ea-339557f8016f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 581ms/step - accuracy: 0.6495 - loss: 0.9046\n",
            "Epoch 2/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 552ms/step - accuracy: 0.9132 - loss: 0.1947\n",
            "Epoch 3/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 545ms/step - accuracy: 0.9257 - loss: 0.1642\n",
            "Epoch 4/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 549ms/step - accuracy: 0.9284 - loss: 0.1826\n",
            "Epoch 5/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 548ms/step - accuracy: 0.9391 - loss: 0.1467\n",
            "Epoch 6/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 549ms/step - accuracy: 0.9569 - loss: 0.0974\n",
            "Epoch 7/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 548ms/step - accuracy: 0.9612 - loss: 0.0909\n",
            "Epoch 8/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 547ms/step - accuracy: 0.9648 - loss: 0.0858\n",
            "Epoch 9/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 547ms/step - accuracy: 0.9678 - loss: 0.0750\n",
            "Epoch 10/10\n",
            "\u001b[1m1020/1020\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 547ms/step - accuracy: 0.9687 - loss: 0.0727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f44e8b2a1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = '/content/drive/MyDrive/weights/Full_Model/pretext_task_weights.weights.h5'\n",
        "pretext_model.save_weights(weights_path)\n",
        "\n",
        "print(f\"Weights saved at: {weights_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDgHoE5RnGJg",
        "outputId": "a2bc1e78-aac2-44f7-b6fd-8e1ce7a86439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights saved at: /content/drive/MyDrive/weights/Full_Model/pretext_task_weights.weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretext_model.load_weights('/content/drive/MyDrive/weights/Full_Model/pretext_task_weights.weights.h5',skip_mismatch=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MkJuX73Ga-3",
        "outputId": "cdb8f27e-f9cd-4df1-f99e-50c51b286efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 434 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminate\n",
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "metadata": {
        "id": "yPVeJoh2nW15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}